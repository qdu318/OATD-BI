{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f67e321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import multivariate_normal as mvnrnd\n",
    "from scipy.stats import wishart\n",
    "from numpy.random import normal as normrnd\n",
    "from scipy.linalg import khatri_rao as kr_prod\n",
    "from numpy.linalg import inv as inv\n",
    "from numpy.linalg import solve as solve\n",
    "from numpy.linalg import cholesky as cholesky_lower\n",
    "from scipy.linalg import cholesky as cholesky_upper\n",
    "from scipy.linalg import solve_triangular as solve_ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55aa9bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mvnrnd_pre(mu, Lambda):\n",
    "    src = normrnd(size = (mu.shape[0],))\n",
    "    return solve_ut(cholesky_upper(Lambda, overwrite_a = True, check_finite = False), \n",
    "                    src, lower = False, check_finite = False, overwrite_b = True) + mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc4ff978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cp_combine(var,G):\n",
    "    temp1 = np.einsum('rpq, tr -> tpq', G, var[0])\n",
    "    temp2 = np.einsum('rpq, tp -> rtq', temp1, var[1])\n",
    "    temp3 = np.einsum('rpq, tq -> rpt', temp2, var[2])\n",
    "    \n",
    "    return temp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fd8fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ten2mat(tensor, mode):\n",
    "    return np.reshape(np.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1), order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "867b6509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat2ten(mat, dim, mode):\n",
    "    index = list()\n",
    "    index.append(mode)\n",
    "    for i in range(dim.shape[0]):\n",
    "        if i != mode:\n",
    "            index.append(i)\n",
    "    return np.moveaxis(np.reshape(mat, list(dim[index]), order = 'F'), 0, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2558d1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_mat(mat, mat_bar):\n",
    "    mat = mat - mat_bar\n",
    "    return mat.T @ mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ba59b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_factor(tau_sparse_tensor, tau_ind, factor, k,G,beta0 = 1):\n",
    "    dim, rank = factor[k].shape\n",
    "    dim = factor[k].shape[0]\n",
    "    #print(\"factor大小\",factor[k].shape)\n",
    "    factor_bar = np.mean(factor[k], axis = 0) #按列来算求均值\n",
    "    temp = dim / (dim + beta0)  #小数\n",
    "    var_mu_hyper = temp * factor_bar \n",
    "    #print(\"var_mu_hyper\",var_mu_hyper.shape)\n",
    "    var_W_hyper = inv(np.eye(rank) + cov_mat(factor[k], factor_bar) + temp * beta0 * np.outer(factor_bar, factor_bar))#协方差矩阵逆\n",
    "    #print(\"var_W_hyper\",var_W_hyper.shape)\n",
    "    var_Lambda_hyper = wishart.rvs(df = dim + rank, scale = var_W_hyper) #wishart协方差矩阵\n",
    "    #print(\"var_Lambda_hyper\",var_Lambda_hyper.shape)\n",
    "    var_mu_hyper = mvnrnd_pre(var_mu_hyper, (dim + beta0) * var_Lambda_hyper) #均值向量\n",
    "    #print(\"var_mu_hyper\",var_mu_hyper.shape)\n",
    "    \n",
    "    idx = list(filter(lambda x: x != k, range(len(factor))))\n",
    "    g=ten2mat(G,k)\n",
    "    #print(\"len\",len(idx))\n",
    "    #print(idx)\n",
    "    #print(\"g\",g.shape)\n",
    "    #print(\"g@\",np.kron(factor[idx[1]], factor[idx[0]]).shape)\n",
    "    var1=g@(np.kron(factor[idx[1]], factor[idx[0]])).T\n",
    "    #print(\"var1\",var1.shape)\n",
    "    var2 = kr_prod(var1, var1)\n",
    "    #print(\"var2\",var2.shape)\n",
    "    var3 = (var2 @ ten2mat(tau_ind, k).T).reshape([rank, rank, dim]) + var_Lambda_hyper[:, :, np.newaxis]\n",
    "    #print(\"var3\",var3.shape)\n",
    "    var4 = var1 @ ten2mat(tau_sparse_tensor, k).T + (var_Lambda_hyper @ var_mu_hyper)[:, np.newaxis]\n",
    "    #print(\"var4\",var4.shape)\n",
    "    for i in range(dim):\n",
    "        factor[k][i, :] = mvnrnd_pre(solve(var3[:, :, i], var4[:, i]), var3[:, :, i])\n",
    "    return factor[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9ffd80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_precision_tau(sparse_tensor, tensor_hat, ind):\n",
    "    var_alpha = 1e-6 + 0.5 * np.sum(ind)\n",
    "    var_beta = 1e-6 + 0.5 * np.sum(((sparse_tensor - tensor_hat) ** 2) * ind)\n",
    "    return np.random.gamma(var_alpha, 1 / var_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89e44d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mape(var, var_hat):\n",
    "    return np.sum(np.abs(var - var_hat) / var) / var.shape[0]\n",
    "\n",
    "def compute_rmse(var, var_hat):\n",
    "    return  np.sqrt(np.sum((var - var_hat) ** 2) / var.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c68e5837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updata_g(G,var,X):\n",
    "    temp1 = np.einsum('rpq, tr -> tpq', X, (np.linalg.pinv(var[0]) ))\n",
    "    temp2 = np.einsum('rpq, tp -> rtq', temp1, (np.linalg.pinv(var[1]) ))\n",
    "    temp3 = np.einsum('rpq, tq -> rpt', temp2, (np.linalg.pinv(var[2]) ))\n",
    "    return temp3\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0fc965ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mar(X, pred_step, maxiter = 100):\n",
    "    T,m, n  = X.shape\n",
    "    B = np.random.randn(n, n)\n",
    "    for it in range(maxiter):\n",
    "        temp0 = B.T @ B\n",
    "        temp1 = np.zeros((m, m))\n",
    "        temp2 = np.zeros((m, m))\n",
    "        for t in range(1, T):\n",
    "            temp1 += X[t,:, :] @ B @ X[t-1,:, :].T\n",
    "            temp2 += X[t - 1,:, :] @ temp0 @ X[t - 1,:, :].T\n",
    "        A = temp1 @ np.linalg.inv(temp2)\n",
    "        temp0 = A.T @ A\n",
    "        temp1 = np.zeros((n, n))\n",
    "        temp2 = np.zeros((n, n))\n",
    "        for t in range(1, T):\n",
    "            temp1 += X[ t,:, :].T @ A @ X[t-1,:, :]\n",
    "            temp2 += X[t-1,:, :].T @ temp0 @ X[t-1,:, :]\n",
    "        B = temp1 @ np.linalg.inv(temp2)\n",
    "    tensor = np.append(X, np.zeros((pred_step,m, n)), axis = 0)\n",
    "    for s in range(pred_step):\n",
    "        tensor[T + s, :, :] = A @ tensor[ T + s - 1,:, :] @ B.T\n",
    "    return tensor[- pred_step ,:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1cdc9274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mar(X, maxiter = 100):\n",
    "    \n",
    "    for i in range(X.shape[2]-1):\n",
    "        X[i,:,:]=mar(X,i+1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e974e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BGCP(dense_tensor, sparse_tensor, factor, burn_iter, gibbs_iter,G):\n",
    "    \"\"\"OATD-BI core code\"\"\"\n",
    "    \n",
    "    dim = np.array(sparse_tensor.shape)\n",
    "    print(\"dim\",sparse_tensor.shape)\n",
    "    rank = factor[0].shape[1]\n",
    "    if np.isnan(sparse_tensor).any() == False:\n",
    "        ind = sparse_tensor != 0\n",
    "        pos_obs = np.where(ind)\n",
    "        pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "    elif np.isnan(sparse_tensor).any() == True:\n",
    "        pos_test = np.where((dense_tensor != 0) & (np.isnan(sparse_tensor)))\n",
    "        ind = ~np.isnan(sparse_tensor)\n",
    "        pos_obs = np.where(ind)\n",
    "        sparse_tensor[np.isnan(sparse_tensor)] = 0\n",
    "    show_iter = 200\n",
    "    tau = 1\n",
    "    factor_plus = []\n",
    "    for k in range(len(dim)):\n",
    "        factor_plus.append(np.zeros((dim[k], rank)))\n",
    "    #print(\"factor_plus\",factor_plus[0].shape)    \n",
    "    temp_hat = np.zeros(dim)\n",
    "    tensor_hat_plus = np.zeros(dim)\n",
    "    for it in range(burn_iter + gibbs_iter):\n",
    "        tau_ind = tau * ind\n",
    "        #print(tau_ind.shape)\n",
    "        tau_sparse_tensor = tau * sparse_tensor\n",
    "        for k in range(len(dim)):\n",
    "            factor[k] = sample_factor(tau_sparse_tensor, tau_ind, factor, k,G)\n",
    "        tensor_hat = cp_combine(factor,G)\n",
    "        if(it==burn_iter + gibbs_iter-1):\n",
    "            print(\"Gupdata\")\n",
    "            G=updata_g(G,factor,tau_sparse_tensor)\n",
    "            G=Mar(G)\n",
    "        temp_hat += tensor_hat\n",
    "        tau = sample_precision_tau(sparse_tensor, tensor_hat, ind)\n",
    "        if it + 1 > burn_iter:\n",
    "            factor_plus = [factor_plus[k] + factor[k] for k in range(len(dim))]\n",
    "            tensor_hat_plus += tensor_hat\n",
    "        if (it + 1) % show_iter == 0 and it < burn_iter:\n",
    "            temp_hat = temp_hat / show_iter\n",
    "            print('Iter: {}'.format(it + 1))\n",
    "            print('MAPE: {:.6}'.format(compute_mape(dense_tensor[pos_test], temp_hat[pos_test])))\n",
    "            print('RMSE: {:.6}'.format(compute_rmse(dense_tensor[pos_test], temp_hat[pos_test])))\n",
    "            temp_hat = np.zeros(sparse_tensor.shape)\n",
    "            print()\n",
    "    \n",
    "    \n",
    "    factor = [i / gibbs_iter for i in factor_plus]\n",
    "    tensor_hat = tensor_hat_plus / gibbs_iter\n",
    "    print('Imputation MAPE: {:.6}'.format(compute_mape(dense_tensor[pos_test], tensor_hat[pos_test])))\n",
    "    print('Imputation RMSE: {:.6}'.format(compute_rmse(dense_tensor[pos_test], tensor_hat[pos_test])))\n",
    "    print()\n",
    "    \n",
    "    return tensor_hat, factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5a4e60f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(arr):\n",
    "    arr_min = np.min(arr)\n",
    "    arr_max = np.max(arr)\n",
    "    return (arr - arr_min) / (arr_max - arr_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b1551b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4887, 1024)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "np.random.seed(1000)\n",
    "\n",
    "missing_rate = 0.4\n",
    "df1 = pd.read_csv(r\"D:\\Learn\\BJ13_M32x32_T30_In.csv\")\n",
    "array1 = df1.to_numpy()\n",
    "#array1=min_max_normalize(array1)\n",
    "print(array1.shape)\n",
    "\n",
    "X0=array1[:320,:]\n",
    "X0=X0.reshape(320,32,32)\n",
    "\n",
    "## Random Missing (RM)\n",
    "dense_tensor = X0\n",
    "dim1, dim2, dim3 = dense_tensor.shape\n",
    "sparse_tensor = dense_tensor * np.round(np.random.rand(dim1, dim2, dim3) + 0.5 - missing_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a7de565c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream"
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim = np.array(sparse_tensor.shape)\n",
    "rank = 32\n",
    "factor = []\n",
    "#G = np.random.normal(0, 1, [rank,rank,rank])\n",
    "G = np.random.randn(rank,rank,rank)\n",
    "print(G.shape)\n",
    "\n",
    "for k in range(len(dim)):\n",
    "    #factor.append(0.1 * np.random.normal(0, 1, [dim[k], rank]))\n",
    "    factor.append(0.1 * np.random.randn(dim[k], rank))\n",
    "burnin_iter = 200\n",
    "gibbs_iter = 200\n",
    "tensor_hat, factor = BGCP(dense_tensor, sparse_tensor, factor, burnin_iter, gibbs_iter,G)\n",
    "end = time.time()\n",
    "print('Running time: %.2f minutes'%((end - start) / 60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7518b609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BERT3",
   "language": "python",
   "name": "bert3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
